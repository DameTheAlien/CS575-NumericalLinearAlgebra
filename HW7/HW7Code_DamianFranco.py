# -*- coding: utf-8 -*-
"""HW7Code_DamianFranco.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SnPUcGxQrPhNHxznt4GiTriblUPXUcu-

# Homework 7
## Damian Franco
## CS-575

This program implements two versions of the power iteration method to predicting the largest eigenvalue and its associated eigenvector. The first implementation is a naive version with no normalization techniques while the second implemenation utilizes normalization techniques to properly compute the eigenvectors associated with the largest eigenvalues predictions.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the required modules
from numpy import *
import numpy as np
import matplotlib.pyplot as plt
import time
from prettytable import PrettyTable
import scipy
import scipy.linalg 
from pprint import pprint
# %matplotlib inline
import math

# Saves the current plot to desktop since working in Google Colab
from google.colab import files
#plt.savefig("my_plot.png", bbox_inches='tight', dpi=300)
#files.download("my_plot.png")

"""# Power Method"""

# Power iteration method, naive approach, not normailzed 
def powerIter(A, x, tol):
  lambdaList = []
  xList = []
  for i in range(tol):
    x = np.dot(A, x)
    eigenVal = abs(x).max()
    x = x / x.max()
    lambdaList.append(eigenVal)
    xList.append(x)
  return eigenVal, x, lambdaList, xList

# Normalized version of power iteration method
def powerIter_Normalized(A, x, tol):
    x_curr = x
    x_curr = x_curr / np.linalg.norm(x_curr) # Intial normalization
    eigenVal = 0
    eigenVec = np.zeros(tol)
    valList = []
    vecList = []

    for i in range(tol):
        y = np.matmul(A, x_curr)
        # Compute eigenvalue
        currEigenVal = np.dot(x_curr, y)
        eigenVal = currEigenVal
        valList.append(eigenVal)
        # Compute eigenvector
        currEigenVec = y / np.linalg.norm(y)
        eigenVec = currEigenVec
        vecList.append(eigenVec)
        # Update current eigenvector
        x_curr = eigenVec
        
    return eigenVal, eigenVec, valList, vecList

x_0 = np.array([0.5, 0.5, 0.5, 0.5])

A = np.array([[3, 1, 4, 1], [5, 9, 2, 6], [5, 3, 5, 8], [9, 7, 9, 3]])

lam, x_new, lamList, xList = powerIter(A, x_0, 20)

print(lam)
print(x_new)

lam_Norm, x_Norm, lamList_Norm, xList_Norm = powerIter_Normalized(A, x_0, 20)

print(lam_Norm)
print(x_Norm)

lamList

xList

lamList_Norm

xList_Norm

print(np.abs(lam - np.matmul(xList_Norm[1].T, np.matmul(A, xList_Norm[1]))))

print(np.abs(lam - np.matmul(xList_Norm[19].T, np.matmul(A, xList_Norm[19]))))

errorLam = []
for i in range(20):
  matMult = np.dot(xList_Norm[i].T, np.dot(A, xList_Norm[i]))
  errApprox = abs(lam - matMult)
  errorLam.append(errApprox)

errorLam

errorFactor = [0.0]
for i in range(1, 20):
  currFact = errorLam[i-1] / errorLam[i]
  errorFactor.append(currFact)

errorFactor

errorVec = []
pm = 1
for i in range(20):
  errVecCurr = np.linalg.norm(x_Norm - pm*xList_Norm[i])
  errorVec.append(errVecCurr)

errorVec

errorVecFactor = [0.0]
for i in range(1, 20):
  if errorVec[i] != 0:
    currFact = errorVec[i-1] / errorVec[i]
    errorVecFactor.append(currFact)
  else:
    errorVecFactor.append(0.0)

errorVecFactor

# Create error table with sizes
# Specify the Column Names while initializing the Table
myTable = PrettyTable(["Iteration", "Estimated EigenVal", "EigenVal Error", "EigenVal Error Factor", "EigenVec Error", "EigenVec Error Factor"])
iterNum = range(1,21)
# Add rows
for i in range(20):
  myTable.add_row([iterNum[i], lamList[i], errorLam[i], errorFactor[i], errorVec[i], errorVecFactor[i]])

print(myTable)